training_args:
  output_dir: outputs
  num_epochs: 100

  learning_rate: 5e-5
  lr_scheduler_type: linear
  warmup_steps: 1000

  train_batch_size: 16
  eval_batch_size: 8
  data_loader_num_workers: 8

  eval_steps: 1500

  use_8bit_adam: true
  gradient_accumulation_steps: 1
  logger: wandb
  mixed_precision: fp16
  save_steps: 1000
  save_total_limit: 3
  resume_from_checkpoint: latest

  seed: 42
  data_seed: 0

  tracker_init_kwargs:
    group: 'anime-face'
    name: 'finetuning-clip-large-anime-face'
    tags: ['anime-face']
    # resume: true

training_module:
  _target_: mugen.trainingmodules.clip.CLIPTrainingModule
  pretrained_name_or_path: laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K
  image_key: image
  text_key: caption
  random_truncation: true

datamodule:
  _target_: mugen.datamodules.ImageDataModule
  data_path: huanngzh/anime_face_control_60k
  train_split: train[:90%]
  val_split: train[90%:]
  image_column: target
  caption_column: prompt
  resolution: 256
  center_normalize: false
