training_args:
  output_dir: outputs
  num_epochs: 2000

  learning_rate: 5e-5
  lr_scheduler_type: constant_with_warmup
  warmup_steps: 1000

  train_batch_size: 32
  eval_batch_size: 4
  data_loader_num_workers: 8

  eval_steps: 2000

  gradient_accumulation_steps: 1
  mixed_precision: fp16
  use_8bit_adam: true

  logger: wandb
  save_steps: 1000
  save_total_limit: 3
  resume_from_checkpoint: latest

  tracker_init_kwargs:
    group: 'anime-face'
    name: 'sd-32-anime-face'
    tags: ['anime-face', 'sd-32']

training_module:
  _target_: mugen.trainingmodules.text2image.Text2ImageTrainingModule
  pretrained_name_or_path: CompVis/stable-diffusion-v1-4
  vae_pretrained_name_or_path: stabilityai/sd-vae-ft-mse
  tokenizer_pretrained_name_or_path: outputs/clip_anime_face/checkpoint-4000/tokenizer
  text_encoder_pretrained_name_or_path: outputs/clip_anime_face/checkpoint-4000/text_encoder
  unet_config:
    sample_size: 32
    cross_attention_dim: 768
    block_out_channels: [256, 256, 512, 512]

  use_ema: true
  enable_xformers_memory_efficient_attention: true
  run_safety_checker: false

datamodule:
  _target_: mugen.datamodules.Text2ImageDataModule
  data_path: huanngzh/anime_face_control_60k
  train_split: train[:95%]
  val_split: train[95%:]
  image_column: target
  caption_column: prompt
  resolution: 256
  random_flip: false
  vae_pretrained_name_or_path: ${training_module.vae_pretrained_name_or_path}
  tokenizer_pretrained_name_or_path: ${training_module.tokenizer_pretrained_name_or_path}
  text_encoder_pretrained_name_or_path: ${training_module.text_encoder_pretrained_name_or_path}
  batch_size: 16
  # load_cached: false
