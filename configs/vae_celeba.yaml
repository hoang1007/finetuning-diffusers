training_args:
  output_dir: outputs
  num_epochs: 100

  learning_rate: 5e-6
  lr_scheduler_type: constant

  train_batch_size: 4
  eval_batch_size: 4
  data_loader_num_workers: 8

  eval_steps: 1000

  gradient_accumulation_steps: 4
  use_8bit_adam: true
  logger: wandb
  mixed_precision: fp16
  save_steps: 1000
  save_total_limit: 3
  resume_from_checkpoint: latest

training_module:
  _target_: mugen.trainingmodules.vae.VAETrainingModule
  pretrained_name_or_path: stabilityai/sd-vae-ft-mse
  freeze_encoder: true
  use_ema: true
  input_key: image
  lpips_config:
    disc_start: 0
    kl_weight: 0.000001
    disc_weight: 0.5

datamodule:
  _target_: mugen.datamodules.celeba.CelebaDataModule
  data_dir: .cache/multi_modal_celeba/data
  resolution: 256
